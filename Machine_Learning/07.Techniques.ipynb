{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card = pd.read_csv('./data/creditcard.csv').drop(columns=\"Time\") #필요없는 열 추출\n",
    "card.head() #Class 0 은 정상, 1은 사기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 목표변수의 범주를 확인하는 것이 가장 먼저\n",
    "card.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 비율이 안맞는 경우 반드시 층화추출 진행\n",
    "target = card.Class\n",
    "card = card.drop(columns='Class')\n",
    "x_train, x_test, y_train, y_test = train_test_split(card, target, test_size=0.3, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998275\n",
       "1    0.001725\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998268\n",
       "1    0.001732\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216496</th>\n",
       "      <td>-0.269383</td>\n",
       "      <td>1.300255</td>\n",
       "      <td>-0.344408</td>\n",
       "      <td>-0.501187</td>\n",
       "      <td>0.722302</td>\n",
       "      <td>-1.098674</td>\n",
       "      <td>1.038838</td>\n",
       "      <td>-0.225951</td>\n",
       "      <td>0.037227</td>\n",
       "      <td>-0.444288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163814</td>\n",
       "      <td>-0.319056</td>\n",
       "      <td>-0.692415</td>\n",
       "      <td>0.179153</td>\n",
       "      <td>1.065445</td>\n",
       "      <td>-0.403436</td>\n",
       "      <td>0.073659</td>\n",
       "      <td>0.206190</td>\n",
       "      <td>0.152384</td>\n",
       "      <td>8.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59888</th>\n",
       "      <td>-1.671138</td>\n",
       "      <td>-0.314642</td>\n",
       "      <td>0.827410</td>\n",
       "      <td>0.191625</td>\n",
       "      <td>-0.516025</td>\n",
       "      <td>0.628207</td>\n",
       "      <td>-0.421132</td>\n",
       "      <td>0.657946</td>\n",
       "      <td>-1.219910</td>\n",
       "      <td>0.806491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024555</td>\n",
       "      <td>-0.176021</td>\n",
       "      <td>0.095142</td>\n",
       "      <td>-0.051342</td>\n",
       "      <td>-0.838746</td>\n",
       "      <td>0.143531</td>\n",
       "      <td>-0.107884</td>\n",
       "      <td>0.483813</td>\n",
       "      <td>0.144208</td>\n",
       "      <td>135.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58094</th>\n",
       "      <td>-3.723656</td>\n",
       "      <td>3.305770</td>\n",
       "      <td>-1.071769</td>\n",
       "      <td>-0.167663</td>\n",
       "      <td>-1.986199</td>\n",
       "      <td>-0.614428</td>\n",
       "      <td>-1.613420</td>\n",
       "      <td>2.777694</td>\n",
       "      <td>-0.833943</td>\n",
       "      <td>-0.011897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094927</td>\n",
       "      <td>-0.026265</td>\n",
       "      <td>-0.459621</td>\n",
       "      <td>0.340770</td>\n",
       "      <td>0.204473</td>\n",
       "      <td>0.089231</td>\n",
       "      <td>0.103482</td>\n",
       "      <td>0.068313</td>\n",
       "      <td>0.019161</td>\n",
       "      <td>8.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>-0.236908</td>\n",
       "      <td>0.848256</td>\n",
       "      <td>2.064695</td>\n",
       "      <td>1.712024</td>\n",
       "      <td>-0.367251</td>\n",
       "      <td>-0.332517</td>\n",
       "      <td>-0.016730</td>\n",
       "      <td>-0.003585</td>\n",
       "      <td>1.021921</td>\n",
       "      <td>-0.338489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053586</td>\n",
       "      <td>0.095002</td>\n",
       "      <td>0.524425</td>\n",
       "      <td>-0.122513</td>\n",
       "      <td>0.301976</td>\n",
       "      <td>-0.410931</td>\n",
       "      <td>-0.150967</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.155086</td>\n",
       "      <td>11.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92938</th>\n",
       "      <td>1.426018</td>\n",
       "      <td>-1.024794</td>\n",
       "      <td>0.528813</td>\n",
       "      <td>-1.441670</td>\n",
       "      <td>-1.401239</td>\n",
       "      <td>-0.354281</td>\n",
       "      <td>-1.087145</td>\n",
       "      <td>0.019586</td>\n",
       "      <td>-2.129068</td>\n",
       "      <td>1.565830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360834</td>\n",
       "      <td>-0.123262</td>\n",
       "      <td>0.047281</td>\n",
       "      <td>0.079524</td>\n",
       "      <td>0.202033</td>\n",
       "      <td>0.259862</td>\n",
       "      <td>-0.206328</td>\n",
       "      <td>0.043906</td>\n",
       "      <td>0.008901</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5899</th>\n",
       "      <td>1.120942</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.149914</td>\n",
       "      <td>0.428457</td>\n",
       "      <td>0.702589</td>\n",
       "      <td>1.545466</td>\n",
       "      <td>-0.453786</td>\n",
       "      <td>0.430930</td>\n",
       "      <td>1.544179</td>\n",
       "      <td>-0.595729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.305578</td>\n",
       "      <td>-0.352394</td>\n",
       "      <td>-0.687808</td>\n",
       "      <td>0.179633</td>\n",
       "      <td>-1.900995</td>\n",
       "      <td>-0.050276</td>\n",
       "      <td>0.239704</td>\n",
       "      <td>0.005608</td>\n",
       "      <td>-0.011886</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282707</th>\n",
       "      <td>1.997387</td>\n",
       "      <td>0.040579</td>\n",
       "      <td>-1.695882</td>\n",
       "      <td>1.198138</td>\n",
       "      <td>0.505815</td>\n",
       "      <td>-0.593284</td>\n",
       "      <td>0.400136</td>\n",
       "      <td>-0.150634</td>\n",
       "      <td>0.208882</td>\n",
       "      <td>0.456681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.352455</td>\n",
       "      <td>0.028360</td>\n",
       "      <td>0.191231</td>\n",
       "      <td>-0.018694</td>\n",
       "      <td>-0.505323</td>\n",
       "      <td>0.372299</td>\n",
       "      <td>-0.524383</td>\n",
       "      <td>-0.025218</td>\n",
       "      <td>-0.075999</td>\n",
       "      <td>13.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6721</th>\n",
       "      <td>-0.449493</td>\n",
       "      <td>0.816512</td>\n",
       "      <td>2.636727</td>\n",
       "      <td>2.105088</td>\n",
       "      <td>-0.215755</td>\n",
       "      <td>0.940100</td>\n",
       "      <td>0.172385</td>\n",
       "      <td>0.111156</td>\n",
       "      <td>0.977004</td>\n",
       "      <td>0.185309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132962</td>\n",
       "      <td>-0.182263</td>\n",
       "      <td>-0.132894</td>\n",
       "      <td>-0.137960</td>\n",
       "      <td>-0.093373</td>\n",
       "      <td>-0.221953</td>\n",
       "      <td>-0.156775</td>\n",
       "      <td>-0.252159</td>\n",
       "      <td>-0.214472</td>\n",
       "      <td>49.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48882</th>\n",
       "      <td>-0.158312</td>\n",
       "      <td>0.383009</td>\n",
       "      <td>2.800678</td>\n",
       "      <td>0.705862</td>\n",
       "      <td>-0.842052</td>\n",
       "      <td>-0.001080</td>\n",
       "      <td>-0.240885</td>\n",
       "      <td>0.067491</td>\n",
       "      <td>0.251563</td>\n",
       "      <td>-0.074534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106367</td>\n",
       "      <td>0.309222</td>\n",
       "      <td>1.142907</td>\n",
       "      <td>-0.090603</td>\n",
       "      <td>0.648966</td>\n",
       "      <td>-0.533228</td>\n",
       "      <td>0.549536</td>\n",
       "      <td>-0.071547</td>\n",
       "      <td>-0.171873</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246640</th>\n",
       "      <td>-0.978218</td>\n",
       "      <td>1.716015</td>\n",
       "      <td>-1.668760</td>\n",
       "      <td>-1.211071</td>\n",
       "      <td>0.714946</td>\n",
       "      <td>-1.174589</td>\n",
       "      <td>0.870260</td>\n",
       "      <td>0.577607</td>\n",
       "      <td>-0.860558</td>\n",
       "      <td>-0.463323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108564</td>\n",
       "      <td>0.352758</td>\n",
       "      <td>0.962002</td>\n",
       "      <td>-0.113354</td>\n",
       "      <td>0.819697</td>\n",
       "      <td>-0.218969</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.246915</td>\n",
       "      <td>0.193985</td>\n",
       "      <td>7.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199020 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "216496 -0.269383  1.300255 -0.344408 -0.501187  0.722302 -1.098674  1.038838   \n",
       "59888  -1.671138 -0.314642  0.827410  0.191625 -0.516025  0.628207 -0.421132   \n",
       "58094  -3.723656  3.305770 -1.071769 -0.167663 -1.986199 -0.614428 -1.613420   \n",
       "10007  -0.236908  0.848256  2.064695  1.712024 -0.367251 -0.332517 -0.016730   \n",
       "92938   1.426018 -1.024794  0.528813 -1.441670 -1.401239 -0.354281 -1.087145   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "5899    1.120942  0.024900  0.149914  0.428457  0.702589  1.545466 -0.453786   \n",
       "282707  1.997387  0.040579 -1.695882  1.198138  0.505815 -0.593284  0.400136   \n",
       "6721   -0.449493  0.816512  2.636727  2.105088 -0.215755  0.940100  0.172385   \n",
       "48882  -0.158312  0.383009  2.800678  0.705862 -0.842052 -0.001080 -0.240885   \n",
       "246640 -0.978218  1.716015 -1.668760 -1.211071  0.714946 -1.174589  0.870260   \n",
       "\n",
       "              V8        V9       V10  ...       V20       V21       V22  \\\n",
       "216496 -0.225951  0.037227 -0.444288  ...  0.163814 -0.319056 -0.692415   \n",
       "59888   0.657946 -1.219910  0.806491  ... -0.024555 -0.176021  0.095142   \n",
       "58094   2.777694 -0.833943 -0.011897  ...  0.094927 -0.026265 -0.459621   \n",
       "10007  -0.003585  1.021921 -0.338489  ...  0.053586  0.095002  0.524425   \n",
       "92938   0.019586 -2.129068  1.565830  ... -0.360834 -0.123262  0.047281   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "5899    0.430930  1.544179 -0.595729  ... -0.305578 -0.352394 -0.687808   \n",
       "282707 -0.150634  0.208882  0.456681  ... -0.352455  0.028360  0.191231   \n",
       "6721    0.111156  0.977004  0.185309  ... -0.132962 -0.182263 -0.132894   \n",
       "48882   0.067491  0.251563 -0.074534  ...  0.106367  0.309222  1.142907   \n",
       "246640  0.577607 -0.860558 -0.463323  ... -0.108564  0.352758  0.962002   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \n",
       "216496  0.179153  1.065445 -0.403436  0.073659  0.206190  0.152384    8.95  \n",
       "59888  -0.051342 -0.838746  0.143531 -0.107884  0.483813  0.144208  135.00  \n",
       "58094   0.340770  0.204473  0.089231  0.103482  0.068313  0.019161    8.96  \n",
       "10007  -0.122513  0.301976 -0.410931 -0.150967  0.167372  0.155086   11.53  \n",
       "92938   0.079524  0.202033  0.259862 -0.206328  0.043906  0.008901   10.00  \n",
       "...          ...       ...       ...       ...       ...       ...     ...  \n",
       "5899    0.179633 -1.900995 -0.050276  0.239704  0.005608 -0.011886    8.99  \n",
       "282707 -0.018694 -0.505323  0.372299 -0.524383 -0.025218 -0.075999   13.99  \n",
       "6721   -0.137960 -0.093373 -0.221953 -0.156775 -0.252159 -0.214472   49.22  \n",
       "48882  -0.090603  0.648966 -0.533228  0.549536 -0.071547 -0.171873    3.92  \n",
       "246640 -0.113354  0.819697 -0.218969  0.040268  0.246915  0.193985    7.70  \n",
       "\n",
       "[199020 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[y_train!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[y_train==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212393</th>\n",
       "      <td>1.878470</td>\n",
       "      <td>0.245783</td>\n",
       "      <td>-0.180231</td>\n",
       "      <td>3.437445</td>\n",
       "      <td>0.516674</td>\n",
       "      <td>1.592014</td>\n",
       "      <td>-0.638221</td>\n",
       "      <td>0.369625</td>\n",
       "      <td>-0.638921</td>\n",
       "      <td>1.491805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139446</td>\n",
       "      <td>0.181526</td>\n",
       "      <td>0.622393</td>\n",
       "      <td>0.091724</td>\n",
       "      <td>-0.202570</td>\n",
       "      <td>-0.109002</td>\n",
       "      <td>0.030728</td>\n",
       "      <td>0.016298</td>\n",
       "      <td>-0.040467</td>\n",
       "      <td>9.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154751</th>\n",
       "      <td>-1.657982</td>\n",
       "      <td>2.286493</td>\n",
       "      <td>2.135218</td>\n",
       "      <td>3.451338</td>\n",
       "      <td>1.485629</td>\n",
       "      <td>3.393304</td>\n",
       "      <td>0.387334</td>\n",
       "      <td>0.133861</td>\n",
       "      <td>1.241333</td>\n",
       "      <td>4.019069</td>\n",
       "      <td>...</td>\n",
       "      <td>1.317243</td>\n",
       "      <td>-0.705193</td>\n",
       "      <td>-0.424659</td>\n",
       "      <td>-0.207059</td>\n",
       "      <td>-1.125212</td>\n",
       "      <td>-0.129007</td>\n",
       "      <td>0.130558</td>\n",
       "      <td>-0.110522</td>\n",
       "      <td>-0.904542</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154830</th>\n",
       "      <td>-2.500050</td>\n",
       "      <td>-1.452786</td>\n",
       "      <td>1.287850</td>\n",
       "      <td>0.205492</td>\n",
       "      <td>3.073167</td>\n",
       "      <td>-0.608714</td>\n",
       "      <td>-0.657685</td>\n",
       "      <td>0.304002</td>\n",
       "      <td>1.015449</td>\n",
       "      <td>-0.936196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130905</td>\n",
       "      <td>-0.252355</td>\n",
       "      <td>-0.804842</td>\n",
       "      <td>0.171384</td>\n",
       "      <td>-1.101881</td>\n",
       "      <td>0.262655</td>\n",
       "      <td>0.452751</td>\n",
       "      <td>-0.352503</td>\n",
       "      <td>0.478977</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95168</th>\n",
       "      <td>1.103283</td>\n",
       "      <td>0.496868</td>\n",
       "      <td>0.721598</td>\n",
       "      <td>2.445562</td>\n",
       "      <td>-0.228412</td>\n",
       "      <td>-0.343509</td>\n",
       "      <td>0.073338</td>\n",
       "      <td>-0.010213</td>\n",
       "      <td>-1.019232</td>\n",
       "      <td>0.859122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107527</td>\n",
       "      <td>0.129063</td>\n",
       "      <td>0.283760</td>\n",
       "      <td>-0.073324</td>\n",
       "      <td>0.535203</td>\n",
       "      <td>0.498646</td>\n",
       "      <td>0.036189</td>\n",
       "      <td>-0.017747</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>21.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18082</th>\n",
       "      <td>1.099958</td>\n",
       "      <td>-1.356570</td>\n",
       "      <td>1.449170</td>\n",
       "      <td>-0.221652</td>\n",
       "      <td>-1.871050</td>\n",
       "      <td>0.700247</td>\n",
       "      <td>-1.471134</td>\n",
       "      <td>0.342701</td>\n",
       "      <td>0.365405</td>\n",
       "      <td>0.419508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290277</td>\n",
       "      <td>-0.371980</td>\n",
       "      <td>-0.374810</td>\n",
       "      <td>-0.067708</td>\n",
       "      <td>0.083449</td>\n",
       "      <td>0.118324</td>\n",
       "      <td>1.103784</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.024030</td>\n",
       "      <td>89.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281019</th>\n",
       "      <td>-0.219055</td>\n",
       "      <td>-0.455172</td>\n",
       "      <td>1.078499</td>\n",
       "      <td>-2.581152</td>\n",
       "      <td>-0.634008</td>\n",
       "      <td>-0.806155</td>\n",
       "      <td>-0.031601</td>\n",
       "      <td>-0.156223</td>\n",
       "      <td>-2.148674</td>\n",
       "      <td>0.686862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332317</td>\n",
       "      <td>-0.101042</td>\n",
       "      <td>0.084335</td>\n",
       "      <td>-0.172197</td>\n",
       "      <td>-0.113627</td>\n",
       "      <td>-0.002392</td>\n",
       "      <td>-0.144527</td>\n",
       "      <td>0.109210</td>\n",
       "      <td>0.121081</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>0.903723</td>\n",
       "      <td>-0.892092</td>\n",
       "      <td>0.719503</td>\n",
       "      <td>0.197674</td>\n",
       "      <td>-0.872965</td>\n",
       "      <td>0.456533</td>\n",
       "      <td>-0.510077</td>\n",
       "      <td>0.166873</td>\n",
       "      <td>1.167482</td>\n",
       "      <td>-0.578552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249406</td>\n",
       "      <td>-0.142681</td>\n",
       "      <td>-0.451460</td>\n",
       "      <td>-0.098689</td>\n",
       "      <td>-0.359964</td>\n",
       "      <td>0.089532</td>\n",
       "      <td>0.987303</td>\n",
       "      <td>-0.045278</td>\n",
       "      <td>0.033586</td>\n",
       "      <td>165.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177792</th>\n",
       "      <td>1.790123</td>\n",
       "      <td>-0.676921</td>\n",
       "      <td>-1.407382</td>\n",
       "      <td>-0.100497</td>\n",
       "      <td>0.537655</td>\n",
       "      <td>1.070630</td>\n",
       "      <td>-0.264394</td>\n",
       "      <td>0.340204</td>\n",
       "      <td>0.930112</td>\n",
       "      <td>-0.189152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203482</td>\n",
       "      <td>-0.040814</td>\n",
       "      <td>0.048374</td>\n",
       "      <td>0.157158</td>\n",
       "      <td>-1.625878</td>\n",
       "      <td>-0.264069</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>-0.072756</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183946</th>\n",
       "      <td>0.417551</td>\n",
       "      <td>1.046155</td>\n",
       "      <td>1.854364</td>\n",
       "      <td>4.573521</td>\n",
       "      <td>-0.390073</td>\n",
       "      <td>1.237692</td>\n",
       "      <td>-0.698513</td>\n",
       "      <td>-0.414954</td>\n",
       "      <td>-1.510601</td>\n",
       "      <td>1.687491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065006</td>\n",
       "      <td>0.585763</td>\n",
       "      <td>-0.815010</td>\n",
       "      <td>0.048625</td>\n",
       "      <td>-0.073064</td>\n",
       "      <td>0.178182</td>\n",
       "      <td>0.181389</td>\n",
       "      <td>0.221868</td>\n",
       "      <td>0.238299</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216343</th>\n",
       "      <td>1.960126</td>\n",
       "      <td>-0.460938</td>\n",
       "      <td>-0.415883</td>\n",
       "      <td>0.534387</td>\n",
       "      <td>-0.506508</td>\n",
       "      <td>-0.064006</td>\n",
       "      <td>-0.647695</td>\n",
       "      <td>0.017954</td>\n",
       "      <td>1.177543</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098840</td>\n",
       "      <td>0.227425</td>\n",
       "      <td>0.830413</td>\n",
       "      <td>0.117788</td>\n",
       "      <td>0.731847</td>\n",
       "      <td>-0.150485</td>\n",
       "      <td>0.413824</td>\n",
       "      <td>-0.011466</td>\n",
       "      <td>-0.034673</td>\n",
       "      <td>29.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "212393  1.878470  0.245783 -0.180231  3.437445  0.516674  1.592014 -0.638221   \n",
       "154751 -1.657982  2.286493  2.135218  3.451338  1.485629  3.393304  0.387334   \n",
       "154830 -2.500050 -1.452786  1.287850  0.205492  3.073167 -0.608714 -0.657685   \n",
       "95168   1.103283  0.496868  0.721598  2.445562 -0.228412 -0.343509  0.073338   \n",
       "18082   1.099958 -1.356570  1.449170 -0.221652 -1.871050  0.700247 -1.471134   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "281019 -0.219055 -0.455172  1.078499 -2.581152 -0.634008 -0.806155 -0.031601   \n",
       "14377   0.903723 -0.892092  0.719503  0.197674 -0.872965  0.456533 -0.510077   \n",
       "177792  1.790123 -0.676921 -1.407382 -0.100497  0.537655  1.070630 -0.264394   \n",
       "183946  0.417551  1.046155  1.854364  4.573521 -0.390073  1.237692 -0.698513   \n",
       "216343  1.960126 -0.460938 -0.415883  0.534387 -0.506508 -0.064006 -0.647695   \n",
       "\n",
       "              V8        V9       V10  ...       V20       V21       V22  \\\n",
       "212393  0.369625 -0.638921  1.491805  ... -0.139446  0.181526  0.622393   \n",
       "154751  0.133861  1.241333  4.019069  ...  1.317243 -0.705193 -0.424659   \n",
       "154830  0.304002  1.015449 -0.936196  ...  0.130905 -0.252355 -0.804842   \n",
       "95168  -0.010213 -1.019232  0.859122  ... -0.107527  0.129063  0.283760   \n",
       "18082   0.342701  0.365405  0.419508  ... -0.290277 -0.371980 -0.374810   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "281019 -0.156223 -2.148674  0.686862  ... -0.332317 -0.101042  0.084335   \n",
       "14377   0.166873  1.167482 -0.578552  ...  0.249406 -0.142681 -0.451460   \n",
       "177792  0.340204  0.930112 -0.189152  ... -0.203482 -0.040814  0.048374   \n",
       "183946 -0.414954 -1.510601  1.687491  ... -0.065006  0.585763 -0.815010   \n",
       "216343  0.017954  1.177543  0.007972  ... -0.098840  0.227425  0.830413   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \n",
       "212393  0.091724 -0.202570 -0.109002  0.030728  0.016298 -0.040467    9.62  \n",
       "154751 -0.207059 -1.125212 -0.129007  0.130558 -0.110522 -0.904542    0.76  \n",
       "154830  0.171384 -1.101881  0.262655  0.452751 -0.352503  0.478977    0.89  \n",
       "95168  -0.073324  0.535203  0.498646  0.036189 -0.017747  0.015899   21.19  \n",
       "18082  -0.067708  0.083449  0.118324  1.103784  0.008250  0.024030   89.00  \n",
       "...          ...       ...       ...       ...       ...       ...     ...  \n",
       "281019 -0.172197 -0.113627 -0.002392 -0.144527  0.109210  0.121081   25.00  \n",
       "14377  -0.098689 -0.359964  0.089532  0.987303 -0.045278  0.033586  165.20  \n",
       "177792  0.157158 -1.625878 -0.264069  0.017921  0.005490 -0.072756   70.00  \n",
       "183946  0.048625 -0.073064  0.178182  0.181389  0.221868  0.238299    3.49  \n",
       "216343  0.117788  0.731847 -0.150485  0.413824 -0.011466 -0.034673   29.90  \n",
       "\n",
       "[344 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[y_train!=1].sample(len(x_train[y_train==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_under = pd.concat([x_train[y_train==1],\n",
    "                           x_train[y_train!=1].sample(len(x_train[y_train==1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14338</th>\n",
       "      <td>1.125336</td>\n",
       "      <td>1.130146</td>\n",
       "      <td>-0.962975</td>\n",
       "      <td>2.675688</td>\n",
       "      <td>0.990075</td>\n",
       "      <td>-0.243318</td>\n",
       "      <td>0.316192</td>\n",
       "      <td>0.122960</td>\n",
       "      <td>-1.143343</td>\n",
       "      <td>-0.369909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138814</td>\n",
       "      <td>-0.166737</td>\n",
       "      <td>-0.521934</td>\n",
       "      <td>-0.112376</td>\n",
       "      <td>-0.592077</td>\n",
       "      <td>0.520791</td>\n",
       "      <td>0.043354</td>\n",
       "      <td>0.015159</td>\n",
       "      <td>0.063612</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223572</th>\n",
       "      <td>-2.729482</td>\n",
       "      <td>3.312495</td>\n",
       "      <td>-4.242710</td>\n",
       "      <td>5.036985</td>\n",
       "      <td>-0.376561</td>\n",
       "      <td>-1.532462</td>\n",
       "      <td>-3.449159</td>\n",
       "      <td>1.856839</td>\n",
       "      <td>-3.623334</td>\n",
       "      <td>-5.653638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164288</td>\n",
       "      <td>0.727415</td>\n",
       "      <td>-0.301432</td>\n",
       "      <td>-0.502433</td>\n",
       "      <td>-0.462309</td>\n",
       "      <td>0.510683</td>\n",
       "      <td>0.046665</td>\n",
       "      <td>0.514646</td>\n",
       "      <td>0.140999</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7550</th>\n",
       "      <td>1.111065</td>\n",
       "      <td>0.545980</td>\n",
       "      <td>0.750707</td>\n",
       "      <td>2.450146</td>\n",
       "      <td>0.191360</td>\n",
       "      <td>0.481849</td>\n",
       "      <td>-0.197253</td>\n",
       "      <td>0.166455</td>\n",
       "      <td>0.417873</td>\n",
       "      <td>0.443854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237992</td>\n",
       "      <td>-0.346103</td>\n",
       "      <td>-0.880483</td>\n",
       "      <td>0.136438</td>\n",
       "      <td>-0.435264</td>\n",
       "      <td>0.138783</td>\n",
       "      <td>-0.270529</td>\n",
       "      <td>-0.027408</td>\n",
       "      <td>0.005097</td>\n",
       "      <td>10.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76555</th>\n",
       "      <td>-7.901421</td>\n",
       "      <td>2.720472</td>\n",
       "      <td>-7.885936</td>\n",
       "      <td>6.348334</td>\n",
       "      <td>-5.480119</td>\n",
       "      <td>-0.333059</td>\n",
       "      <td>-8.682376</td>\n",
       "      <td>1.164431</td>\n",
       "      <td>-4.542447</td>\n",
       "      <td>-7.748480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.614719</td>\n",
       "      <td>0.077739</td>\n",
       "      <td>1.092437</td>\n",
       "      <td>0.320133</td>\n",
       "      <td>-0.434643</td>\n",
       "      <td>-0.380687</td>\n",
       "      <td>0.213630</td>\n",
       "      <td>0.423620</td>\n",
       "      <td>-0.105169</td>\n",
       "      <td>153.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47861</th>\n",
       "      <td>-1.006202</td>\n",
       "      <td>0.092331</td>\n",
       "      <td>1.496653</td>\n",
       "      <td>-0.363712</td>\n",
       "      <td>-1.587107</td>\n",
       "      <td>-0.301888</td>\n",
       "      <td>0.533989</td>\n",
       "      <td>0.410532</td>\n",
       "      <td>0.345198</td>\n",
       "      <td>-1.365756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225587</td>\n",
       "      <td>0.109596</td>\n",
       "      <td>0.074284</td>\n",
       "      <td>0.644150</td>\n",
       "      <td>0.761522</td>\n",
       "      <td>-0.875199</td>\n",
       "      <td>0.610491</td>\n",
       "      <td>-0.058289</td>\n",
       "      <td>0.140372</td>\n",
       "      <td>212.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42696</th>\n",
       "      <td>-8.426814</td>\n",
       "      <td>6.241659</td>\n",
       "      <td>-9.946470</td>\n",
       "      <td>8.199614</td>\n",
       "      <td>-8.213093</td>\n",
       "      <td>-2.522046</td>\n",
       "      <td>-11.643028</td>\n",
       "      <td>5.339500</td>\n",
       "      <td>-7.051016</td>\n",
       "      <td>-12.265324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563869</td>\n",
       "      <td>2.427460</td>\n",
       "      <td>0.692667</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>0.499809</td>\n",
       "      <td>0.467594</td>\n",
       "      <td>0.483162</td>\n",
       "      <td>1.195671</td>\n",
       "      <td>0.198294</td>\n",
       "      <td>88.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160382</th>\n",
       "      <td>-2.714436</td>\n",
       "      <td>3.044536</td>\n",
       "      <td>-3.305199</td>\n",
       "      <td>-1.406683</td>\n",
       "      <td>-0.145586</td>\n",
       "      <td>-1.043348</td>\n",
       "      <td>-0.347337</td>\n",
       "      <td>1.959858</td>\n",
       "      <td>-0.585882</td>\n",
       "      <td>-0.078788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116362</td>\n",
       "      <td>0.370652</td>\n",
       "      <td>0.744213</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.239676</td>\n",
       "      <td>0.026430</td>\n",
       "      <td>0.087697</td>\n",
       "      <td>0.046768</td>\n",
       "      <td>0.184859</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31002</th>\n",
       "      <td>-5.685013</td>\n",
       "      <td>5.776516</td>\n",
       "      <td>-7.064977</td>\n",
       "      <td>5.902715</td>\n",
       "      <td>-4.715564</td>\n",
       "      <td>-1.755633</td>\n",
       "      <td>-6.958679</td>\n",
       "      <td>3.877795</td>\n",
       "      <td>-5.541529</td>\n",
       "      <td>-7.502112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299489</td>\n",
       "      <td>1.128641</td>\n",
       "      <td>-0.962960</td>\n",
       "      <td>-0.110045</td>\n",
       "      <td>-0.177733</td>\n",
       "      <td>-0.089175</td>\n",
       "      <td>-0.049447</td>\n",
       "      <td>0.303445</td>\n",
       "      <td>0.219380</td>\n",
       "      <td>111.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6641</th>\n",
       "      <td>0.857321</td>\n",
       "      <td>4.093912</td>\n",
       "      <td>-7.423894</td>\n",
       "      <td>7.380245</td>\n",
       "      <td>0.973366</td>\n",
       "      <td>-2.730762</td>\n",
       "      <td>-1.496497</td>\n",
       "      <td>0.543015</td>\n",
       "      <td>-2.351190</td>\n",
       "      <td>-3.944238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483303</td>\n",
       "      <td>0.375026</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.240603</td>\n",
       "      <td>-0.234649</td>\n",
       "      <td>-1.004881</td>\n",
       "      <td>0.435832</td>\n",
       "      <td>0.618324</td>\n",
       "      <td>0.148469</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11351</th>\n",
       "      <td>1.288024</td>\n",
       "      <td>-0.295505</td>\n",
       "      <td>0.688362</td>\n",
       "      <td>-0.709518</td>\n",
       "      <td>-0.740265</td>\n",
       "      <td>-0.294616</td>\n",
       "      <td>-0.671149</td>\n",
       "      <td>-0.060929</td>\n",
       "      <td>3.167726</td>\n",
       "      <td>-1.453241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121894</td>\n",
       "      <td>-0.211844</td>\n",
       "      <td>-0.135007</td>\n",
       "      <td>-0.136811</td>\n",
       "      <td>-0.492933</td>\n",
       "      <td>0.583957</td>\n",
       "      <td>-0.674169</td>\n",
       "      <td>0.063544</td>\n",
       "      <td>0.022187</td>\n",
       "      <td>11.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6         V7  \\\n",
       "14338   1.125336  1.130146 -0.962975  2.675688  0.990075 -0.243318   0.316192   \n",
       "223572 -2.729482  3.312495 -4.242710  5.036985 -0.376561 -1.532462  -3.449159   \n",
       "7550    1.111065  0.545980  0.750707  2.450146  0.191360  0.481849  -0.197253   \n",
       "76555  -7.901421  2.720472 -7.885936  6.348334 -5.480119 -0.333059  -8.682376   \n",
       "47861  -1.006202  0.092331  1.496653 -0.363712 -1.587107 -0.301888   0.533989   \n",
       "...          ...       ...       ...       ...       ...       ...        ...   \n",
       "42696  -8.426814  6.241659 -9.946470  8.199614 -8.213093 -2.522046 -11.643028   \n",
       "160382 -2.714436  3.044536 -3.305199 -1.406683 -0.145586 -1.043348  -0.347337   \n",
       "31002  -5.685013  5.776516 -7.064977  5.902715 -4.715564 -1.755633  -6.958679   \n",
       "6641    0.857321  4.093912 -7.423894  7.380245  0.973366 -2.730762  -1.496497   \n",
       "11351   1.288024 -0.295505  0.688362 -0.709518 -0.740265 -0.294616  -0.671149   \n",
       "\n",
       "              V8        V9        V10  ...       V20       V21       V22  \\\n",
       "14338   0.122960 -1.143343  -0.369909  ... -0.138814 -0.166737 -0.521934   \n",
       "223572  1.856839 -3.623334  -5.653638  ...  0.164288  0.727415 -0.301432   \n",
       "7550    0.166455  0.417873   0.443854  ... -0.237992 -0.346103 -0.880483   \n",
       "76555   1.164431 -4.542447  -7.748480  ... -0.614719  0.077739  1.092437   \n",
       "47861   0.410532  0.345198  -1.365756  ...  0.225587  0.109596  0.074284   \n",
       "...          ...       ...        ...  ...       ...       ...       ...   \n",
       "42696   5.339500 -7.051016 -12.265324  ...  0.563869  2.427460  0.692667   \n",
       "160382  1.959858 -0.585882  -0.078788  ... -0.116362  0.370652  0.744213   \n",
       "31002   3.877795 -5.541529  -7.502112  ...  0.299489  1.128641 -0.962960   \n",
       "6641    0.543015 -2.351190  -3.944238  ...  0.483303  0.375026  0.145400   \n",
       "11351  -0.060929  3.167726  -1.453241  ... -0.121894 -0.211844 -0.135007   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \n",
       "14338  -0.112376 -0.592077  0.520791  0.043354  0.015159  0.063612    3.76  \n",
       "223572 -0.502433 -0.462309  0.510683  0.046665  0.514646  0.140999    1.00  \n",
       "7550    0.136438 -0.435264  0.138783 -0.270529 -0.027408  0.005097   10.25  \n",
       "76555   0.320133 -0.434643 -0.380687  0.213630  0.423620 -0.105169  153.46  \n",
       "47861   0.644150  0.761522 -0.875199  0.610491 -0.058289  0.140372  212.96  \n",
       "...          ...       ...       ...       ...       ...       ...     ...  \n",
       "42696   0.020305  0.499809  0.467594  0.483162  1.195671  0.198294   88.23  \n",
       "160382  0.061540  0.239676  0.026430  0.087697  0.046768  0.184859    0.77  \n",
       "31002  -0.110045 -0.177733 -0.089175 -0.049447  0.303445  0.219380  111.70  \n",
       "6641    0.240603 -0.234649 -1.004881  0.435832  0.618324  0.148469    1.00  \n",
       "11351  -0.136811 -0.492933  0.583957 -0.674169  0.063544  0.022187   11.85  \n",
       "\n",
       "[688 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_under.sample(len(x_train_under)) #1인 경우와 0인 경우가 연속적으로 이어져 있으므로, 한 번 섞어줘야 학습 효과가 좋음\n",
    "# x_train_under = x_train_under.sort_index() 도 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_under = y_train[x_train_under.index] #x_train_under의 y 값 찾기 후 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "x_train_over, y_train_over = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398040, 29)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199020\n",
       "1    199020\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dt_param = {'criterion':['gini','entropy'],\n",
    "            'max_depth':np.arange(1,31)}\n",
    "\n",
    "dt01 = DecisionTreeClassifier()\n",
    "dt02 = DecisionTreeClassifier()\n",
    "dt03 = DecisionTreeClassifier()\n",
    "dt01_best = GridSearchCV(dt01, dt_param, scoring = 'roc_auc', n_jobs=-1, cv=4)\n",
    "dt02_best = GridSearchCV(dt02, dt_param, scoring = 'roc_auc', n_jobs=-1, cv=4)\n",
    "dt03_best = GridSearchCV(dt03, dt_param, scoring = 'roc_auc', n_jobs=-1, cv=4)\n",
    "\n",
    "dt01_best.fit(x_train, y_train)\n",
    "dt02_best.fit(x_train_under, y_train_under)\n",
    "dt03_best.fit(x_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 3}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt01_best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt02_best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 12}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt03_best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt01_best.best_estimator_ #가장 최적일 때 모델 학습 결과\n",
    "dt01_best = dt01_best.best_estimator_ #이렇게 진행하면 그리드 서치한 결과가 없어지지만, 메모리 사용량을 줄일 수 있음\n",
    "dt02_best = dt02_best.best_estimator_\n",
    "dt03_best = dt03_best.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW정확도:0.9325\n",
      "UNDER정확도:0.9516\n",
      "OVER정확도:0.8985\n"
     ]
    }
   ],
   "source": [
    "#여러 모델을 비교할 땐, 순환문 활용이 좋음\n",
    "from sklearn.metrics import roc_auc_score\n",
    "models = [dt01_best, dt02_best, dt03_best]\n",
    "model_names = ['RAW','UNDER','OVER']\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    pred = model.predict_proba(x_test)[:,1] #1일 확률\n",
    "    print('{0}정확도:{1:.4f}'.format(name, roc_auc_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  \n",
       "0               1        101348.88       1  \n",
       "1               1        112542.58       0  \n",
       "2               0        113931.57       1  \n",
       "3               0         93826.63       0  \n",
       "4               1         79084.10       0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn = pd.read_csv('./data/churn.csv')\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2022)\n",
    "target = churn.Exited\n",
    "churn = churn.drop(columns='Exited')\n",
    "x_train, x_test, y_train, y_test = train_test_split(churn, target, test_size=0.3,\n",
    "                                                   stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('standardscaler', StandardScaler()), ('logisticregression', LogisticRegression())]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),LogisticRegression())\n",
    "print(pipe.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train, y_train)\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_rawAUC:0.6728\n",
      "pipe_simpleAUC:0.7544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "models = [lr, pipe]\n",
    "model_names = ['lr_raw','pipe_simple']\n",
    "for model,name in zip(models,model_names):\n",
    "    pred = model.predict_proba(x_test)[:,1]\n",
    "    print('{0}AUC:{1:.4f}'.format(name,roc_auc_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('standardscaler', StandardScaler()), ('logisticregression', LogisticRegression())]\n"
     ]
    }
   ],
   "source": [
    "# Grid Search Example\n",
    "pipe_grid = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "print(pipe_grid.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1, 10,\n",
       "                                                   100],\n",
       "                         &#x27;logisticregression__max_iter&#x27;: [100, 200, 300]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1, 10,\n",
       "                                                   100],\n",
       "                         &#x27;logisticregression__max_iter&#x27;: [100, 200, 300]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logisticregression__C': [0.001, 0.01, 0.1, 1, 10,\n",
       "                                                   100],\n",
       "                         'logisticregression__max_iter': [100, 200, 300]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#기존 그리드 서치 : lr_param = {'C':[0.001,0.01, 0.1, 1, 10, 100]}\n",
    "lr_param = {'logisticregression__C':[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "           'logisticregression__max_iter':[100,200,300]} # 조절하고 싶은 파라미터 추가 방법\n",
    "\n",
    "grid = GridSearchCV(pipe_grid, lr_param, cv=5, n_jobs=-1, verbose=1)\n",
    "grid.fit(x_train, y_train) # pipe 가 아닌 grid 를 fit 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_rawAUC:0.6728\n",
      "pipe_simpleAUC:0.7544\n",
      "pipe_gridAUC:0.7545\n"
     ]
    }
   ],
   "source": [
    "models = [lr, pipe, lr_grid]\n",
    "model_names = ['lr_raw','pipe_simple','pipe_grid']\n",
    "for model,name in zip(models,model_names):\n",
    "    pred = model.predict_proba(x_test)[:,1]\n",
    "    print('{0}AUC:{1:.4f}'.format(name,roc_auc_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('전처리',StandardScaler()),('알고리즘',LogisticRegression())]) #파이프라인 진행에 대한 예제 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [\n",
    "    {'전처리':[StandardScaler()],\n",
    "    '알고리즘':[LogisticRegression()],\n",
    "    '알고리즘__C':[0.01, 0.1, 1, 10]},\n",
    "    {'전처리':[StandardScaler(), None],\n",
    "    '알고리즘':[KNeighborsClassifier()],\n",
    "    '알고리즘__n_neighbors':[10,20,30,40,50,100,200]},\n",
    "    {'전처리':[MinMaxScaler(), None],\n",
    "    '알고리즘':[DecisionTreeClassifier()],\n",
    "    '알고리즘__max_depth':np.arange(2,11)}]\n",
    "# {} 가 하나의 파이프라인 set가 되며 Gridsearch 로 넘기게 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[(&#x27;전처리&#x27;, StandardScaler()),\n",
       "                                       (&#x27;알고리즘&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;알고리즘&#x27;: [LogisticRegression()],\n",
       "                          &#x27;알고리즘__C&#x27;: [0.01, 0.1, 1, 10],\n",
       "                          &#x27;전처리&#x27;: [StandardScaler()]},\n",
       "                         {&#x27;알고리즘&#x27;: [KNeighborsClassifier()],\n",
       "                          &#x27;알고리즘__n_neighbors&#x27;: [10, 20, 30, 40, 50, 100, 200],\n",
       "                          &#x27;전처리&#x27;: [StandardScaler(), None]},\n",
       "                         {&#x27;알고리즘&#x27;: [DecisionTreeClassifier(max_depth=5)],\n",
       "                          &#x27;알고리즘__max_depth&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                          &#x27;전처리&#x27;: [MinMaxScaler(), None]}],\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[(&#x27;전처리&#x27;, StandardScaler()),\n",
       "                                       (&#x27;알고리즘&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;알고리즘&#x27;: [LogisticRegression()],\n",
       "                          &#x27;알고리즘__C&#x27;: [0.01, 0.1, 1, 10],\n",
       "                          &#x27;전처리&#x27;: [StandardScaler()]},\n",
       "                         {&#x27;알고리즘&#x27;: [KNeighborsClassifier()],\n",
       "                          &#x27;알고리즘__n_neighbors&#x27;: [10, 20, 30, 40, 50, 100, 200],\n",
       "                          &#x27;전처리&#x27;: [StandardScaler(), None]},\n",
       "                         {&#x27;알고리즘&#x27;: [DecisionTreeClassifier(max_depth=5)],\n",
       "                          &#x27;알고리즘__max_depth&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                          &#x27;전처리&#x27;: [MinMaxScaler(), None]}],\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;전처리&#x27;, StandardScaler()), (&#x27;알고리즘&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[('전처리', StandardScaler()),\n",
       "                                       ('알고리즘', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'알고리즘': [LogisticRegression()],\n",
       "                          '알고리즘__C': [0.01, 0.1, 1, 10],\n",
       "                          '전처리': [StandardScaler()]},\n",
       "                         {'알고리즘': [KNeighborsClassifier()],\n",
       "                          '알고리즘__n_neighbors': [10, 20, 30, 40, 50, 100, 200],\n",
       "                          '전처리': [StandardScaler(), None]},\n",
       "                         {'알고리즘': [DecisionTreeClassifier(max_depth=5)],\n",
       "                          '알고리즘__max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                          '전처리': [MinMaxScaler(), None]}],\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe, param, scoring='roc_auc', cv=4, n_jobs=-1, verbose=1)\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'알고리즘': DecisionTreeClassifier(max_depth=5),\n",
       " '알고리즘__max_depth': 5,\n",
       " '전처리': MinMaxScaler()}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8434018712333329"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "pred = grid.predict_proba(x_test)[:,1] # 1일 확률값\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=4,\n",
       "                   estimator=Pipeline(steps=[(&#x27;전처리&#x27;, StandardScaler()),\n",
       "                                             (&#x27;알고리즘&#x27;, LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions=[{&#x27;알고리즘&#x27;: [LogisticRegression()],\n",
       "                                         &#x27;알고리즘__C&#x27;: [0.01, 0.1, 1, 10],\n",
       "                                         &#x27;전처리&#x27;: [StandardScaler()]},\n",
       "                                        {&#x27;알고리즘&#x27;: [KNeighborsClassifier()],\n",
       "                                         &#x27;알고리즘__n_neighbors&#x27;: [10, 20, 30, 40,\n",
       "                                                               50, 100, 200],\n",
       "                                         &#x27;전처리&#x27;: [StandardScaler(), None]},\n",
       "                                        {&#x27;알고리즘&#x27;: [DecisionTreeClassifier(max_depth=5)],\n",
       "                                         &#x27;알고리즘__max_depth&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                         &#x27;전처리&#x27;: [MinMaxScaler(), None]}],\n",
       "                   scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=4,\n",
       "                   estimator=Pipeline(steps=[(&#x27;전처리&#x27;, StandardScaler()),\n",
       "                                             (&#x27;알고리즘&#x27;, LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions=[{&#x27;알고리즘&#x27;: [LogisticRegression()],\n",
       "                                         &#x27;알고리즘__C&#x27;: [0.01, 0.1, 1, 10],\n",
       "                                         &#x27;전처리&#x27;: [StandardScaler()]},\n",
       "                                        {&#x27;알고리즘&#x27;: [KNeighborsClassifier()],\n",
       "                                         &#x27;알고리즘__n_neighbors&#x27;: [10, 20, 30, 40,\n",
       "                                                               50, 100, 200],\n",
       "                                         &#x27;전처리&#x27;: [StandardScaler(), None]},\n",
       "                                        {&#x27;알고리즘&#x27;: [DecisionTreeClassifier(max_depth=5)],\n",
       "                                         &#x27;알고리즘__max_depth&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                         &#x27;전처리&#x27;: [MinMaxScaler(), None]}],\n",
       "                   scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;전처리&#x27;, StandardScaler()), (&#x27;알고리즘&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=4,\n",
       "                   estimator=Pipeline(steps=[('전처리', StandardScaler()),\n",
       "                                             ('알고리즘', LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions=[{'알고리즘': [LogisticRegression()],\n",
       "                                         '알고리즘__C': [0.01, 0.1, 1, 10],\n",
       "                                         '전처리': [StandardScaler()]},\n",
       "                                        {'알고리즘': [KNeighborsClassifier()],\n",
       "                                         '알고리즘__n_neighbors': [10, 20, 30, 40,\n",
       "                                                               50, 100, 200],\n",
       "                                         '전처리': [StandardScaler(), None]},\n",
       "                                        {'알고리즘': [DecisionTreeClassifier(max_depth=5)],\n",
       "                                         '알고리즘__max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                         '전처리': [MinMaxScaler(), None]}],\n",
       "                   scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_grid = RandomizedSearchCV(pipe, param, n_iter=20, scoring='roc_auc', cv=4, n_jobs=-1, verbose=1)\n",
    "# n_inter를 60번 이상 진행하게 되면, 최적의 파라미터를 뽑아낼 수 있다\n",
    "random_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'전처리': MinMaxScaler(),\n",
       " '알고리즘__max_depth': 5,\n",
       " '알고리즘': DecisionTreeClassifier(max_depth=5)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68756eb6c044f31c46e3e1f38723aea1f0146198488dd3d60c0e4241eb6f7dd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
